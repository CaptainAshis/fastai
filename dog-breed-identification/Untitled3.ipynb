{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) DROPOUT:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dropout is a type of regularization . Regularization is used to reduce overfitting which means it is used to make sure that the model doesnt overlearn \n",
    "from the training set data and causes problem generalizing to validation or test set data.\n",
    "In normal regularization we penalize the weights to be as small as possible so that the effect of the hidden unit associated with it will be minimum.\n",
    "Hence learning complex descision boundary will be less.\n",
    "\n",
    "In Dropout regularization we set a threshold probability  for a layer and do a random toss at each hidden unit of the layer between 0 and 1  . If that random \n",
    "probability value is less than threshold we drop that hidden unit else we keep it . In this way we convert the complicated bigger network into\n",
    "smaller simple network . Hence learning of complex decision boundary is less and overfitting is prevented.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://quirkyai.files.wordpress.com/2017/06/bootstrap-aggregating-img2.png?w=1000\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='https://quirkyai.files.wordpress.com/2017/06/bootstrap-aggregating-img2.png?w=1000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) RESIDUAL BLOCKS:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Residual blocks are part of Resnet . When we train a network deeper , it stops performing well on training data set . Also small features like for e.g if we are training \n",
    "a face detection ,small features like mole in the face goes unnoticed. Hence using residual blocks those features can be brought to prominence.\n",
    "To turn a plain network into a network of residual blocks we can add the extra skip connections . Make sure to check the dimensions of the feature vectors\n",
    "when we are adding after doing a skip connection.\n",
    "The image looks like this :-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/376/1*pUyst_ciesOz_LUg0HocYg.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "from IPython.display import Image\n",
    "Image(url='https://cdn-images-1.medium.com/max/376/1*pUyst_ciesOz_LUg0HocYg.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A lot of such blocks makes up a  ResNet.\n",
    "\n",
    "Using this concept we can train our Neural network much better by allowing it to go into deeper layer and helps resolving the problem of vanishing and exploding\n",
    "gradients . By using this concept we can train deep Neural network without much loss in performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) 1 by 1 CONVOLUTION:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 by 1 convolution is also known as network in network convolution.\n",
    "Suppose we have a 6 by 6 by 32 feature map and we do a 1 by 1 convolution then the 1 by 1 filter will look at the 36 different position\n",
    "and will take an elementwise product for all the 32 elements and sum it up .The main use of 1 by 1 convolution is to shrink the\n",
    "number of channels.\n",
    "The number of output channel we want will depend on the number of 1 by 1 filter that we are using.\n",
    "So couple of points to remember:-\n",
    "1) In CNN when we want to shrink number of channels we use 1 by 1 convolution .\n",
    "2) In CNN when we want to shrink the height and width of the feature map we use Pooling Layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ytimg.com/vi/rWbz33rMfMQ/maxresdefault.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='https://i.ytimg.com/vi/rWbz33rMfMQ/maxresdefault.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXECUTE SCRIPT ANALYTICS_SCV.SCRIPT_MASTER (\n",
    "# 'TEST_CLS_CAM_AP_1',\n",
    "# null,\n",
    "# 'CDNA_ADHOC_SCV.CAMP_AP_1',\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# 'CDNA_ADHOC_SCV.GENE_ADID_2',\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# null,\n",
    "# 'EUR',\n",
    "# null\n",
    "# )\n",
    "# with\n",
    "#output;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # execute script analytics_Scv.SCRIPT_MASTER(\n",
    "# # 'TEST_CLS_CAM_AP_1',\n",
    "# null,\n",
    "# ']]..EXTERNAL_DATASET..[['\n",
    "# , null,\n",
    "# NULL, \n",
    "# NULL,\n",
    "# #  null,\n",
    "# NULL, \n",
    "# NULL,\n",
    "# NULL,\n",
    "# NULL,\n",
    "# NULL, \n",
    "# NULL,\n",
    "# NULL, \n",
    "# 'CDNA_ADHOC_SCV.GENE_ADID_2',\n",
    "# NULL,\n",
    "# NULL,\n",
    "# NULL, \n",
    "# NULL,\n",
    "# NULL,\n",
    "# #  NULL,\n",
    "# NULL, \n",
    "# NULL,\n",
    "# NULL,\n",
    "# NULL,\n",
    "# NULL, \n",
    "# NULL, \n",
    "# NULL,\n",
    "# NULL,\n",
    "# NULL,\n",
    "# NULL,\n",
    "# NULL,\n",
    "# NULL, \n",
    "# NULL,\n",
    "# 'EUR', \n",
    "# null ) with output ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
